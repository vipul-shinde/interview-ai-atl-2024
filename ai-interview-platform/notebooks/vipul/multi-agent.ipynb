{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import os\n",
    "import yaml\n",
    "from crewai import Agent, LLM, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "from tools.video_feedback import upload_video_and_get_summary\n",
    "from tools.video_tool import UploadVideoAndGetSummaryTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key=\"AIzaSyAg2zlHo7alqplyszLDItc5Ch_DeqBNs1Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the gemini models\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-1.5-pro-latest\", \n",
    "    temperature=0.5,\n",
    "    api_key=google_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML configurations for agents and tasks\n",
    "files = {\n",
    "    'data_scientist_agents': 'config/data_scientist_agents.yaml',\n",
    "    'data_scientist_tasks': 'config/data_scientist_tasks.yaml',\n",
    "    'feedback_agents': 'config/feedback_agents.yaml',\n",
    "    'feedback_agent_tasks': 'config/feedback_agent_tasks.yaml',\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "        \n",
    "# Assign loaded configurations to specific variables\n",
    "data_scientist_agents_config = configs['data_scientist_agents']\n",
    "data_scientist_tasks_config = configs['data_scientist_tasks']\n",
    "feedback_agents_config = configs['feedback_agents']\n",
    "feedback_agent_tasks_config = configs['feedback_agent_tasks']\n",
    "\n",
    "with open('prompt_video.txt', 'r') as file:\n",
    "    video_prompt = file.read()\n",
    "    \n",
    "with open('video_transcript.txt', 'r') as file:\n",
    "    video_transcript = file.read()\n",
    "    \n",
    "with open('final_prompt.txt', 'r') as file:\n",
    "    final_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 23:55:46,309 - 8300711744 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "data_scientist_agent = Agent(\n",
    "  config=data_scientist_agents_config['data_scientist_interviewer'],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "feedback_agent = Agent(\n",
    "  config=feedback_agents_config['feedback_agent'],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "data_scientist_task = Task(\n",
    "  config=data_scientist_tasks_config['generate_interview_questions'],\n",
    "  agent=data_scientist_agent\n",
    ")\n",
    "\n",
    "video_gemini_task = Task(\n",
    "  config=feedback_agent_tasks_config['process_video_with_gemini'],\n",
    "  agent=feedback_agent,\n",
    "  tools = [upload_video_and_get_summary]\n",
    ")\n",
    "\n",
    "# final_feedback_task = Task(\n",
    "#   config=feedback_agent_tasks_config['generate_final_feedback_report'],\n",
    "#   agent=feedback_agent\n",
    "# )\n",
    "\n",
    "interview_crew = Crew(\n",
    "  agents=[\n",
    "    data_scientist_agent,\n",
    "  ],\n",
    "  tasks=[\n",
    "    data_scientist_task,\n",
    "  ],\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "feedback_crew = Crew(\n",
    "  agents=[\n",
    "    feedback_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    final_feedback_task\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Interviewer Role:** Senior Data Scientist Interviewer\n",
       "\n",
       "**Interview Length:** 3\n",
       "\n",
       "**Interview Type:** technical, behavioral\n",
       "\n",
       "**Role Focus:** data science and machine learning\n",
       "\n",
       "**Interviewer Position:** Lead Data Scientist\n",
       "\n",
       "**Expertise Area:** machine learning, statistics, and data analysis\n",
       "\n",
       "**Industry:** finance\n",
       "\n",
       "**Role Level:** mid-senior\n",
       "\n",
       "**Role Title:** Data Scientist\n",
       "\n",
       "**Specialization:** machine learning\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "interviewer_role = 'Senior Data Scientist Interviewer'\n",
    "interview_length = '3'\n",
    "interview_type = 'technical, behavioral'\n",
    "role_focus = 'data science and machine learning'\n",
    "interviewer_position = 'Lead Data Scientist'\n",
    "expertise_areas = 'machine learning, statistics, and data analysis'\n",
    "industry = 'finance'\n",
    "role_level = 'mid-senior'\n",
    "role_title = 'Data Scientist'\n",
    "specialization = 'machine learning'\n",
    "\n",
    "# Format the dictionary as Markdown for better display\n",
    "formatted_output = f\"\"\"\n",
    "**Interviewer Role:** {interviewer_role}\n",
    "\n",
    "**Interview Length:** {interview_length}\n",
    "\n",
    "**Interview Type:** {interview_type}\n",
    "\n",
    "**Role Focus:** {role_focus}\n",
    "\n",
    "**Interviewer Position:** {interviewer_position}\n",
    "\n",
    "**Expertise Area:** {expertise_areas}\n",
    "\n",
    "**Industry:** {industry}\n",
    "\n",
    "**Role Level:** {role_level}\n",
    "\n",
    "**Role Title:** {role_title}\n",
    "\n",
    "**Specialization:** {specialization}\n",
    "\"\"\"\n",
    "\n",
    "# Display the formatted output as Markdown\n",
    "display(Markdown(formatted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Data Scientist Interviewer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCreate a set of interview questions suitable for a 3-minute technical, behavioral interview for a mid-senior Data Scientist position.\n",
      "The questions should cover general concepts in data science and machine learning, as well as some aspects related to the finance industry. Ensure that not all questions are focused on the specified industry, to assess the candidate's overall expertise.\n",
      "Focus on the following key areas:\n",
      "- Technical Expertise:\n",
      "  - Core concepts relevant to machine learning and general data science practices.\n",
      "  - Programming skills in languages and frameworks commonly used in this role.\n",
      "\n",
      "- Problem-Solving Ability:\n",
      "  - Scenarios that assess analytical thinking and approach to real-world problems, both industry-agnostic and some related to finance.\n",
      "\n",
      "- Project Experience:\n",
      "  - Questions about past projects that demonstrate required skills for a mid-senior role.\n",
      "\n",
      "- Soft Skills:\n",
      "  - Communication and teamwork abilities.\n",
      "  - For senior roles, leadership and mentoring skills.\n",
      "\n",
      "- Cultural Fit:\n",
      "  - Alignment with our company's values and mission.\n",
      "  - Motivation and career goals related to the Data Scientist position.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Data Scientist Interviewer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**Technical Expertise:**\n",
      "\n",
      "1. **Explain the bias-variance trade-off in the context of machine learning models. How do you balance this trade-off when building a model?** (Assesses understanding of core ML concepts)\n",
      "2. **Describe your experience with different types of machine learning algorithms (e.g., supervised, unsupervised, reinforcement learning). Which ones are you most comfortable working with?** (Evaluates breadth and depth of ML knowledge)\n",
      "3. **What are some common data preprocessing techniques used in machine learning? Explain how you would handle missing data in a dataset.** (Tests understanding of data cleaning and preparation)\n",
      "\n",
      "**Problem-Solving Ability:**\n",
      "\n",
      "1. **Imagine you are tasked with building a fraud detection system for credit card transactions. How would you approach this problem from a data science perspective?** (Assesses analytical thinking and problem-solving skills in a finance context)\n",
      "2. **You have a dataset with a high number of features. How would you go about selecting the most relevant features for your machine learning model?** (Evaluates feature engineering and dimensionality reduction techniques)\n",
      "\n",
      "**Project Experience:**\n",
      "\n",
      "1. **Describe a challenging machine learning project you worked on. What were the biggest obstacles you faced, and how did you overcome them?** (Assesses experience with real-world ML projects and problem-solving skills)\n",
      "2. **Have you ever had to present complex technical information to a non-technical audience? How did you ensure they understood the key takeaways?** (Evaluates communication skills and ability to explain technical concepts)\n",
      "\n",
      "**Soft Skills:**\n",
      "\n",
      "1. **Describe a situation where you had to collaborate with others to achieve a common goal. What was your role, and how did you contribute to the team's success?** (Assesses teamwork and collaboration skills)\n",
      "\n",
      "**Cultural Fit:**\n",
      "\n",
      "1. **What are your career aspirations, and how does this position align with your goals?** (Evaluates motivation and career goals)\n",
      "2. **Our company values continuous learning and innovation. Can you share an example of how you have demonstrated these values in your previous work?** (Assesses alignment with company culture)\u001b[00m\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StructuredTool' object has no attribute 'model_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterviewer_role\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSenior Data Scientist Interviewer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterview_length\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterview_transcript\u001b[39m\u001b[38;5;124m'\u001b[39m: video_transcript\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mprep_crew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/crew.py:494\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    491\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/crew.py:598\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    597\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/crew.py:696\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    693\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    695\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 696\u001b[0m task_output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [task_output]\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/task.py:191\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    186\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    187\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    188\u001b[0m     tools: Optional[List[Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/task.py:247\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    243\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[0;32m--> 247\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    255\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    256\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    257\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/agent.py:220\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    217\u001b[0m         task_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi18n\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(memory\u001b[38;5;241m=\u001b[39mmemory)\n\u001b[1;32m    219\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_agent_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew\u001b[38;5;241m.\u001b[39m_train:\n\u001b[1;32m    223\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_handler(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/agent.py:292\u001b[0m, in \u001b[0;36mAgent.create_agent_executor\u001b[0;34m(self, tools, task)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_template:\n\u001b[1;32m    276\u001b[0m     stop_words\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_template\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m .Response }}\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor \u001b[38;5;241m=\u001b[39m CrewAgentExecutor(\n\u001b[1;32m    281\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm,\n\u001b[1;32m    282\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    283\u001b[0m     agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    284\u001b[0m     crew\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrew,\n\u001b[1;32m    285\u001b[0m     tools\u001b[38;5;241m=\u001b[39mparsed_tools,\n\u001b[1;32m    286\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    287\u001b[0m     original_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    288\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39mstop_words,\n\u001b[1;32m    289\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m    290\u001b[0m     tools_handler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools_handler,\n\u001b[1;32m    291\u001b[0m     tools_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__tools_names(parsed_tools),\n\u001b[0;32m--> 292\u001b[0m     tools_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_text_description_and_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_tools\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    293\u001b[0m     step_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_callback,\n\u001b[1;32m    294\u001b[0m     function_calling_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_calling_llm,\n\u001b[1;32m    295\u001b[0m     respect_context_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrespect_context_window,\n\u001b[1;32m    296\u001b[0m     request_within_rpm_limit\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller\u001b[38;5;241m.\u001b[39mcheck_or_wait \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     ),\n\u001b[1;32m    299\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[TokenCalcHandler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_process)],\n\u001b[1;32m    300\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/crewai/agent.py:397\u001b[0m, in \u001b[0;36mAgent._render_text_description_and_args\u001b[0;34m(self, tools)\u001b[0m\n\u001b[1;32m    395\u001b[0m tool_strings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[0;32m--> 397\u001b[0m     args_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fields\u001b[49m)\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tool, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[1;32m    399\u001b[0m         sig \u001b[38;5;241m=\u001b[39m signature(tool\u001b[38;5;241m.\u001b[39mfunc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StructuredTool' object has no attribute 'model_fields'"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    'interviewer_role': 'Senior Data Scientist Interviewer',\n",
    "    'interview_length': '3',  \n",
    "    'interview_type': 'technical, behavioral',\n",
    "    'role_focus': 'data science and machine learning',\n",
    "    'interviewer_position': 'Lead Data Scientist',\n",
    "    'expertise_areas': 'machine learning, statistics, and data analysis',\n",
    "    'industry': 'finance',\n",
    "    'role_level': 'mid-senior',\n",
    "    'role_title': 'Data Scientist',\n",
    "    'specialization': 'machine learning',\n",
    "    'analysis_prompt': video_prompt,\n",
    "    'final_prompt': final_prompt,\n",
    "    'video_file_path': 'test_gemini.mp4',\n",
    "    'feedback_guidelines': final_prompt,\n",
    "    'video_file_path': 'test_gemini.mp4',\n",
    "    'interview_transcript': video_transcript\n",
    "}\n",
    "\n",
    "result = prep_crew.kickoff(\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Flow\n",
    "from crewai.flow.flow import listen, start\n",
    "\n",
    "class InterviewPipeline(Flow):\n",
    "    @start()\n",
    "    def get_details(self):\n",
    "        inputs = {\n",
    "            'interviewer_role': 'Senior Data Scientist Interviewer',\n",
    "            'interview_length': '3',  \n",
    "            'interview_type': 'technical, behavioral',\n",
    "            'role_focus': 'data science and machine learning',\n",
    "            'interviewer_position': 'Lead Data Scientist',\n",
    "            'expertise_areas': 'machine learning, statistics, and data analysis',\n",
    "            'industry': 'finance',\n",
    "            'role_level': 'mid-senior',\n",
    "            'role_title': 'Data Scientist',\n",
    "            'specialization': 'machine learning',\n",
    "            # 'video_prompt': video_prompt,\n",
    "            # 'analysis_prompt': video_transcript,\n",
    "            'feedback_guidelines': final_prompt,\n",
    "            'video_file_path': 'test_gemini.mp4',\n",
    "            'interview_transcript': video_transcript\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "    @listen('get_details')\n",
    "    def generate_questions(self, inputs):\n",
    "        questions = interview_crew.kickoff(\n",
    "            inputs=inputs\n",
    "        )\n",
    "        return questions\n",
    "    \n",
    "    # @listen('generate_questions')\n",
    "    # def start_interview(self, questions):\n",
    "    #     video_path = ''\n",
    "    #     transcript = ''\n",
    "        \n",
    "    # return video_path, transcript\n",
    "    \n",
    "    @listen('generate_questions')\n",
    "    def get_video_feedback(self, inputs):\n",
    "        response = upload_video_and_get_summary(inputs['video_file_path'], inputs['video_prompt'])\n",
    "        return response\n",
    "    \n",
    "    @listen('get_video_feedback')\n",
    "    def get_final_feedback(self, inputs, response):\n",
    "        inputs['gemini_feedback'] = response\n",
    "        feedback = feedback_crew.kickoff(\n",
    "            inputs=inputs\n",
    "        )\n",
    "        return feedback\n",
    "    \n",
    "flow =  InterviewPipeline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as crewai_flow.html\n"
     ]
    }
   ],
   "source": [
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'test_gemini.mp4' as: https://generativelanguage.googleapis.com/v1beta/files/140j7splmr4w\n",
      "Waiting for file processing...\n",
      "....all files ready\n",
      "\n",
      "Gemini API Response: This short clip shows a man wearing a red astronaut suit and helmet standing in a desert landscape. He appears to be speaking to the camera, likely introducing a segment or video about space or desert exploration. The sandy terrain and clear blue sky suggest a remote and arid location.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "video_path = \"test_gemini.mp4\"\n",
    "prompt = \"Please summarize the content of this video.\"\n",
    "response = upload_video_and_get_summary(video_path, prompt)\n",
    "print(\"Gemini API Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
